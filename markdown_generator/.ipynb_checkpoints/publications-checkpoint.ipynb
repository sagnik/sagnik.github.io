{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Publications markdown generator for academicpages\n",
    "\n",
    "Takes a TSV of publications with metadata and converts them for use with [academicpages.github.io](academicpages.github.io). This is an interactive Jupyter notebook ([see more info here](http://jupyter-notebook-beginner-guide.readthedocs.io/en/latest/what_is_jupyter.html)). The core python code is also in `publications.py`. Run either from the `markdown_generator` folder after replacing `publications.tsv` with one containing your data.\n",
    "\n",
    "TODO: Make this work with BibTex and other databases of citations, rather than Stuart's non-standard TSV format and citation style.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data format\n",
    "\n",
    "The TSV needs to have the following columns: pub_date, title, venue, excerpt, citation, site_url, and paper_url, with a header at the top. \n",
    "\n",
    "- `excerpt` and `paper_url` can be blank, but the others must have values. \n",
    "- `pub_date` must be formatted as YYYY-MM-DD.\n",
    "- `url_slug` will be the descriptive part of the .md file and the permalink URL for the page about the paper. The .md file will be `YYYY-MM-DD-[url_slug].md` and the permalink will be `https://[yourdomain]/publications/YYYY-MM-DD-[url_slug]`\n",
    "\n",
    "This is how the raw file looks (it doesn't look pretty, use a spreadsheet or other program to edit and create)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pub_date\ttitle\tvenue\texcerpt\tcitation\turl_slug\tpaper_url\r\n",
      "2009-10-01\tPaper Title Number 1\tJournal 1\tThis paper is about the number 1. The number 2 is left for future work.\tYour Name, You. (2009). \"Paper Title Number 1.\" <i>Journal 1</i>. 1(1).\tpaper-title-number-1\thttp://academicpages.github.io/files/paper1.pdf\r\n",
      "2010-10-01\tPaper Title Number 2\tJournal 1\tThis paper is about the number 2. The number 3 is left for future work.\tYour Name, You. (2010). \"Paper Title Number 2.\" <i>Journal 1</i>. 1(2).\tpaper-title-number-2\thttp://academicpages.github.io/files/paper2.pdf\r\n",
      "2015-10-01\tPaper Title Number 3\tJournal 1\tThis paper is about the number 3. The number 4 is left for future work.\tYour Name, You. (2015). \"Paper Title Number 3.\" <i>Journal 1</i>. 1(3).\tpaper-title-number-3\thttp://academicpages.github.io/files/paper3.pdf"
     ]
    }
   ],
   "source": [
    "!cat publications.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import pandas\n",
    "\n",
    "We are using the very handy pandas library for dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import TSV\n",
    "\n",
    "Pandas makes this easy with the read_csv function. We are using a TSV, so we specify the separator as a tab, or `\\t`.\n",
    "\n",
    "I found it important to put this data in a tab-separated values format, because there are a lot of commas in this kind of data and comma-separated values can get messed up. However, you can modify the import statement, as pandas also has read_excel(), read_json(), and others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pub_date</th>\n",
       "      <th>title</th>\n",
       "      <th>venue</th>\n",
       "      <th>key-words</th>\n",
       "      <th>url_slug</th>\n",
       "      <th>paper_url</th>\n",
       "      <th>dataset</th>\n",
       "      <th>code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021</td>\n",
       "      <td>Can Edge Probing Tasks Reveal Linguistic Knowl...</td>\n",
       "      <td>In submission</td>\n",
       "      <td>edge probing, diagonastic classifiers, QA</td>\n",
       "      <td>ep-qa</td>\n",
       "      <td>https://arxiv.org/pdf/2109.07102.pdf</td>\n",
       "      <td>TBA</td>\n",
       "      <td>TBA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021</td>\n",
       "      <td>Quantifying Gender Bias Towards Politicians in...</td>\n",
       "      <td>In submission</td>\n",
       "      <td>gender bias, BERT, Roberta</td>\n",
       "      <td>gender-bias-lm</td>\n",
       "      <td>https://arxiv.org/pdf/2104.07505.pdf</td>\n",
       "      <td>standard datasets</td>\n",
       "      <td>TBA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021</td>\n",
       "      <td>Intent Features for Rich Natural Language Unde...</td>\n",
       "      <td>NAACL Industry track</td>\n",
       "      <td>dialog systems, intent</td>\n",
       "      <td>intent-features</td>\n",
       "      <td>https://arxiv.org/pdf/2104.08701.pdf</td>\n",
       "      <td>proprietary dataset</td>\n",
       "      <td>https://github.com/dpressel/baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020</td>\n",
       "      <td>Constrained Decoding for Computationally Effic...</td>\n",
       "      <td>EMNLP Findings</td>\n",
       "      <td>CRF, BLSTM, decoding</td>\n",
       "      <td>crf-decoding</td>\n",
       "      <td>https://arxiv.org/pdf/2010.04362.pdf</td>\n",
       "      <td>standard datasets</td>\n",
       "      <td>https://github.com/dpressel/baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020</td>\n",
       "      <td>Multiple Word Embeddings for Increased Diversi...</td>\n",
       "      <td>arxiv</td>\n",
       "      <td>word-embeddings, diversity</td>\n",
       "      <td>we-diversity</td>\n",
       "      <td>https://arxiv.org/pdf/2009.14394.pdf</td>\n",
       "      <td>standard datasets</td>\n",
       "      <td>https://github.com/dpressel/baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2018</td>\n",
       "      <td>Baseline: Strong, Extensible, Reproducible, De...</td>\n",
       "      <td>Neurips MLOSS</td>\n",
       "      <td>DNN library, baseline</td>\n",
       "      <td>baseline-v2</td>\n",
       "      <td>https://openreview.net/pdf?id=rkxp6taEhQ</td>\n",
       "      <td>-</td>\n",
       "      <td>https://github.com/dpressel/baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2018</td>\n",
       "      <td>Text extraction and retrieval from smartphone ...</td>\n",
       "      <td>ACM SAC</td>\n",
       "      <td>screenomics</td>\n",
       "      <td>screenomics</td>\n",
       "      <td>https://arxiv.org/pdf/1801.01316.pdf</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2018</td>\n",
       "      <td>Baseline: A Library for Rapid Modeling, Experi...</td>\n",
       "      <td>ACL NLP-OSS</td>\n",
       "      <td>DNN library, baseline</td>\n",
       "      <td>baseline-v1</td>\n",
       "      <td>https://aclanthology.org/W18-2506.pdf</td>\n",
       "      <td>-</td>\n",
       "      <td>https://github.com/dpressel/baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2017</td>\n",
       "      <td>HESDK: A hybrid approach to extracting scienti...</td>\n",
       "      <td>JCDL</td>\n",
       "      <td>scientific keyword extraction, sequence labeling</td>\n",
       "      <td>hedsk</td>\n",
       "      <td>https://www.cs.odu.edu/~jwu/downloads/pubs/wu-...</td>\n",
       "      <td>SemEval 2017 task 10</td>\n",
       "      <td>https://github.com/SeerLabs/semeval2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2016</td>\n",
       "      <td>Scalable algorithms for scholarly figure minin...</td>\n",
       "      <td>SBD @ SIGMOD</td>\n",
       "      <td>figure-mining, semantics</td>\n",
       "      <td>sbdsemantics</td>\n",
       "      <td>http://clgiles.ist.psu.edu/pubs/SDB-SIGMOD2016...</td>\n",
       "      <td>https://github.com/sagnik/figure-text-classifi...</td>\n",
       "      <td>https://github.com/sagnik/pychartprocessing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2016</td>\n",
       "      <td>Curve separation for line graphs in scholarly ...</td>\n",
       "      <td>JCDL</td>\n",
       "      <td>figure-mining, semantics</td>\n",
       "      <td>jcdlcurvesep</td>\n",
       "      <td>http://www.personal.psu.edu/sxw327/files/JCDL2...</td>\n",
       "      <td>https://drive.google.com/drive/folders/0B65bQn...</td>\n",
       "      <td>https://github.com/sagnik/pychartprocessing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2016</td>\n",
       "      <td>Automatic summary generation for scientific da...</td>\n",
       "      <td>AAAI</td>\n",
       "      <td>figure-mining, semantics</td>\n",
       "      <td>aaai-bar-chart</td>\n",
       "      <td>https://www.aaai.org/ocs/index.php/WS/AAAIW16/...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2015</td>\n",
       "      <td>Automatic extraction of figures from scholarly...</td>\n",
       "      <td>DocEng</td>\n",
       "      <td>figure-extraction, classification</td>\n",
       "      <td>doceng-fig-extraction</td>\n",
       "      <td>https://clgiles.ist.psu.edu/pubs/doceng2015-sr...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2015</td>\n",
       "      <td>Pdfmef: A multi-entity knowledge extraction fr...</td>\n",
       "      <td>KCAP</td>\n",
       "      <td>pdfmef</td>\n",
       "      <td>pdfmef</td>\n",
       "      <td>https://clgiles.ist.psu.edu/pubs/KCAP2015-PDFM...</td>\n",
       "      <td>-</td>\n",
       "      <td>https://github.com/SeerLabs/pdfmef</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2015</td>\n",
       "      <td>An architecture for information extraction fro...</td>\n",
       "      <td>WWW, Companion Volume</td>\n",
       "      <td>info-extractio-arch</td>\n",
       "      <td>arch-www</td>\n",
       "      <td>http://personal.psu.edu/szr163/ketwww15.pdf</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2015</td>\n",
       "      <td>On the relationship between open access and al...</td>\n",
       "      <td>iConference</td>\n",
       "      <td>altmetrics, OA</td>\n",
       "      <td>altmetrics-oa</td>\n",
       "      <td>https://www.ideals.illinois.edu/bitstream/hand...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2014</td>\n",
       "      <td>Keyword and keyphrase extraction using central...</td>\n",
       "      <td>arxiv</td>\n",
       "      <td>keyword extraction, unsupervised methods</td>\n",
       "      <td>keyword-comparison</td>\n",
       "      <td>https://arxiv.org/pdf/1401.6571.pdf</td>\n",
       "      <td>standard datasets</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2014</td>\n",
       "      <td>Towards building a scholarly big data platform...</td>\n",
       "      <td>JCDL</td>\n",
       "      <td>scholarly big data, architecture</td>\n",
       "      <td>sbd-arch</td>\n",
       "      <td>https://clgiles.ist.psu.edu/pubs/JCDL2014-buil...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2014</td>\n",
       "      <td>Scholarly big data information extraction and ...</td>\n",
       "      <td>ICDE</td>\n",
       "      <td>scholarly big data, architecture</td>\n",
       "      <td>sbd-arch-2</td>\n",
       "      <td>http://citeseerx.ist.psu.edu/viewdoc/download?...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2013</td>\n",
       "      <td>Figure metadata extraction from digital documents</td>\n",
       "      <td>ICDAR</td>\n",
       "      <td>figure metadata extraction</td>\n",
       "      <td>fig-metadata-icdar</td>\n",
       "      <td>http://personal.psu.edu/szr163/icdar13.pdf</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2013</td>\n",
       "      <td>A figure search engine architecture for a chem...</td>\n",
       "      <td>JCDL</td>\n",
       "      <td>fig-search</td>\n",
       "      <td>fig-search-jcdl</td>\n",
       "      <td>https://citeseerx.ist.psu.edu/viewdoc/download...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2013</td>\n",
       "      <td>Unsupervised ranking for plagiarism source ret...</td>\n",
       "      <td>CLEF</td>\n",
       "      <td>plagiarism source retrieval</td>\n",
       "      <td>clef-psr</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2012</td>\n",
       "      <td>A Framework for Bridging the Gap Between Open ...</td>\n",
       "      <td>OSIR@SIGIR</td>\n",
       "      <td>search tools</td>\n",
       "      <td>search-tools</td>\n",
       "      <td>https://www.researchgate.net/profile/Benno-Ste...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    pub_date                                              title  \\\n",
       "0       2021  Can Edge Probing Tasks Reveal Linguistic Knowl...   \n",
       "1       2021  Quantifying Gender Bias Towards Politicians in...   \n",
       "2       2021  Intent Features for Rich Natural Language Unde...   \n",
       "3       2020  Constrained Decoding for Computationally Effic...   \n",
       "4       2020  Multiple Word Embeddings for Increased Diversi...   \n",
       "5       2018  Baseline: Strong, Extensible, Reproducible, De...   \n",
       "6       2018  Text extraction and retrieval from smartphone ...   \n",
       "7       2018  Baseline: A Library for Rapid Modeling, Experi...   \n",
       "8       2017  HESDK: A hybrid approach to extracting scienti...   \n",
       "9       2016  Scalable algorithms for scholarly figure minin...   \n",
       "10      2016  Curve separation for line graphs in scholarly ...   \n",
       "11      2016  Automatic summary generation for scientific da...   \n",
       "12      2015  Automatic extraction of figures from scholarly...   \n",
       "13      2015  Pdfmef: A multi-entity knowledge extraction fr...   \n",
       "14      2015  An architecture for information extraction fro...   \n",
       "15      2015  On the relationship between open access and al...   \n",
       "16      2014  Keyword and keyphrase extraction using central...   \n",
       "17      2014  Towards building a scholarly big data platform...   \n",
       "18      2014  Scholarly big data information extraction and ...   \n",
       "19      2013  Figure metadata extraction from digital documents   \n",
       "20      2013  A figure search engine architecture for a chem...   \n",
       "21      2013  Unsupervised ranking for plagiarism source ret...   \n",
       "22      2012  A Framework for Bridging the Gap Between Open ...   \n",
       "\n",
       "                    venue                                         key-words  \\\n",
       "0           In submission         edge probing, diagonastic classifiers, QA   \n",
       "1           In submission                        gender bias, BERT, Roberta   \n",
       "2    NAACL Industry track                            dialog systems, intent   \n",
       "3          EMNLP Findings                              CRF, BLSTM, decoding   \n",
       "4                   arxiv                        word-embeddings, diversity   \n",
       "5           Neurips MLOSS                             DNN library, baseline   \n",
       "6                 ACM SAC                                       screenomics   \n",
       "7             ACL NLP-OSS                             DNN library, baseline   \n",
       "8                    JCDL  scientific keyword extraction, sequence labeling   \n",
       "9            SBD @ SIGMOD                          figure-mining, semantics   \n",
       "10                   JCDL                          figure-mining, semantics   \n",
       "11                   AAAI                          figure-mining, semantics   \n",
       "12                 DocEng                 figure-extraction, classification   \n",
       "13                   KCAP                                            pdfmef   \n",
       "14  WWW, Companion Volume                               info-extractio-arch   \n",
       "15            iConference                                    altmetrics, OA   \n",
       "16                  arxiv          keyword extraction, unsupervised methods   \n",
       "17                   JCDL                  scholarly big data, architecture   \n",
       "18                   ICDE                  scholarly big data, architecture   \n",
       "19                  ICDAR                        figure metadata extraction   \n",
       "20                   JCDL                                        fig-search   \n",
       "21                   CLEF                      plagiarism source retrieval    \n",
       "22             OSIR@SIGIR                                      search tools   \n",
       "\n",
       "                 url_slug                                          paper_url  \\\n",
       "0                   ep-qa               https://arxiv.org/pdf/2109.07102.pdf   \n",
       "1          gender-bias-lm               https://arxiv.org/pdf/2104.07505.pdf   \n",
       "2         intent-features               https://arxiv.org/pdf/2104.08701.pdf   \n",
       "3            crf-decoding               https://arxiv.org/pdf/2010.04362.pdf   \n",
       "4            we-diversity               https://arxiv.org/pdf/2009.14394.pdf   \n",
       "5             baseline-v2           https://openreview.net/pdf?id=rkxp6taEhQ   \n",
       "6             screenomics               https://arxiv.org/pdf/1801.01316.pdf   \n",
       "7             baseline-v1              https://aclanthology.org/W18-2506.pdf   \n",
       "8                   hedsk  https://www.cs.odu.edu/~jwu/downloads/pubs/wu-...   \n",
       "9            sbdsemantics  http://clgiles.ist.psu.edu/pubs/SDB-SIGMOD2016...   \n",
       "10           jcdlcurvesep  http://www.personal.psu.edu/sxw327/files/JCDL2...   \n",
       "11         aaai-bar-chart  https://www.aaai.org/ocs/index.php/WS/AAAIW16/...   \n",
       "12  doceng-fig-extraction  https://clgiles.ist.psu.edu/pubs/doceng2015-sr...   \n",
       "13                 pdfmef  https://clgiles.ist.psu.edu/pubs/KCAP2015-PDFM...   \n",
       "14               arch-www        http://personal.psu.edu/szr163/ketwww15.pdf   \n",
       "15          altmetrics-oa  https://www.ideals.illinois.edu/bitstream/hand...   \n",
       "16     keyword-comparison                https://arxiv.org/pdf/1401.6571.pdf   \n",
       "17               sbd-arch  https://clgiles.ist.psu.edu/pubs/JCDL2014-buil...   \n",
       "18             sbd-arch-2  http://citeseerx.ist.psu.edu/viewdoc/download?...   \n",
       "19     fig-metadata-icdar         http://personal.psu.edu/szr163/icdar13.pdf   \n",
       "20        fig-search-jcdl  https://citeseerx.ist.psu.edu/viewdoc/download...   \n",
       "21               clef-psr                                                  -   \n",
       "22           search-tools  https://www.researchgate.net/profile/Benno-Ste...   \n",
       "\n",
       "                                              dataset  \\\n",
       "0                                                 TBA   \n",
       "1                                   standard datasets   \n",
       "2                                 proprietary dataset   \n",
       "3                                   standard datasets   \n",
       "4                                   standard datasets   \n",
       "5                                                   -   \n",
       "6                                                   -   \n",
       "7                                                   -   \n",
       "8                                SemEval 2017 task 10   \n",
       "9   https://github.com/sagnik/figure-text-classifi...   \n",
       "10  https://drive.google.com/drive/folders/0B65bQn...   \n",
       "11                                                  -   \n",
       "12                                                  -   \n",
       "13                                                  -   \n",
       "14                                                  -   \n",
       "15                                                  -   \n",
       "16                                  standard datasets   \n",
       "17                                                  -   \n",
       "18                                                  -   \n",
       "19                                                  -   \n",
       "20                                                  -   \n",
       "21                                                  -   \n",
       "22                                                  -   \n",
       "\n",
       "                                           code  \n",
       "0                                           TBA  \n",
       "1                                           TBA  \n",
       "2          https://github.com/dpressel/baseline  \n",
       "3          https://github.com/dpressel/baseline  \n",
       "4          https://github.com/dpressel/baseline  \n",
       "5          https://github.com/dpressel/baseline  \n",
       "6                                             -  \n",
       "7          https://github.com/dpressel/baseline  \n",
       "8       https://github.com/SeerLabs/semeval2017  \n",
       "9   https://github.com/sagnik/pychartprocessing  \n",
       "10  https://github.com/sagnik/pychartprocessing  \n",
       "11                                            -  \n",
       "12                                            -  \n",
       "13           https://github.com/SeerLabs/pdfmef  \n",
       "14                                            -  \n",
       "15                                            -  \n",
       "16                                          NaN  \n",
       "17                                            -  \n",
       "18                                            -  \n",
       "19                                            -  \n",
       "20                                            -  \n",
       "21                                            -  \n",
       "22                                            -  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "publications = pd.read_csv(\"papers.tsv\", sep=\"\\t\", header=0)\n",
    "publications\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Escape special characters\n",
    "\n",
    "YAML is very picky about how it takes a valid string, so we are replacing single and double quotes (and ampersands) with their HTML encoded equivilents. This makes them look not so readable in raw format, but they are parsed and rendered nicely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_escape_table = {\n",
    "    \"&\": \"&amp;\",\n",
    "    '\"': \"&quot;\",\n",
    "    \"'\": \"&apos;\"\n",
    "    }\n",
    "\n",
    "def html_escape(text):\n",
    "    \"\"\"Produce entities within text.\"\"\"\n",
    "    return \"\".join(html_escape_table.get(c,c) for c in text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the markdown files\n",
    "\n",
    "This is where the heavy lifting is done. This loops through all the rows in the TSV dataframe, then starts to concatentate a big string (```md```) that contains the markdown for each type. It does the YAML metadata first, then does the description for the individual page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-592da968cbd3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmd_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpub_date\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"-\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl_slug\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".md\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mhtml_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpub_date\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"-\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl_slug\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0myear\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpub_date\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m## YAML variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "import os\n",
    "for row, item in publications.iterrows():\n",
    "    \n",
    "    md_filename = str(item.pub_date) + \"-\" + item.url_slug + \".md\"\n",
    "    html_filename = str(item.pub_date) + \"-\" + item.url_slug\n",
    "    year = item.pub_date[:4]\n",
    "    \n",
    "    ## YAML variables\n",
    "    \n",
    "    md = \"---\\ntitle: \\\"\"   + item.title + '\"\\n'\n",
    "    \n",
    "    md += \"\"\"collection: publications\"\"\"\n",
    "    \n",
    "    md += \"\"\"\\npermalink: /publication/\"\"\" + html_filename\n",
    "    \n",
    "    if len(str(item.excerpt)) > 5:\n",
    "        md += \"\\nexcerpt: '\" + html_escape(item.excerpt) + \"'\"\n",
    "    \n",
    "    md += \"\\ndate: \" + str(item.pub_date) \n",
    "    \n",
    "    md += \"\\nvenue: '\" + html_escape(item.venue) + \"'\"\n",
    "    \n",
    "    if len(str(item.paper_url)) > 5:\n",
    "        md += \"\\npaperurl: '\" + item.paper_url + \"'\"\n",
    "    \n",
    "    md += \"\\ncitation: '\" + html_escape(item.citation) + \"'\"\n",
    "    \n",
    "    md += \"\\n---\"\n",
    "    \n",
    "    ## Markdown description for individual page\n",
    "        \n",
    "    if len(str(item.excerpt)) > 5:\n",
    "        md += \"\\n\" + html_escape(item.excerpt) + \"\\n\"\n",
    "    \n",
    "    if len(str(item.paper_url)) > 5:\n",
    "        md += \"\\n[Download paper here](\" + item.paper_url + \")\\n\" \n",
    "        \n",
    "    md += \"\\nRecommended citation: \" + item.citation\n",
    "    \n",
    "    md_filename = os.path.basename(md_filename)\n",
    "       \n",
    "    with open(\"../_publications/\" + md_filename, 'w') as f:\n",
    "        f.write(md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These files are in the publications directory, one directory below where we're working from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2009-10-01-paper-title-number-1.md 2015-10-01-paper-title-number-3.md\r\n",
      "2010-10-01-paper-title-number-2.md\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../_publications/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\r\n",
      "title: \"Paper Title Number 1\"\r\n",
      "collection: publications\r\n",
      "permalink: /publication/2009-10-01-paper-title-number-1\r\n",
      "excerpt: 'This paper is about the number 1. The number 2 is left for future work.'\r\n",
      "date: 2009-10-01\r\n",
      "venue: 'Journal 1'\r\n",
      "paperurl: 'http://academicpages.github.io/files/paper1.pdf'\r\n",
      "citation: 'Your Name, You. (2009). &quot;Paper Title Number 1.&quot; <i>Journal 1</i>. 1(1).'\r\n",
      "---\r\n",
      "This paper is about the number 1. The number 2 is left for future work.\r\n",
      "\r\n",
      "[Download paper here](http://academicpages.github.io/files/paper1.pdf)\r\n",
      "\r\n",
      "Recommended citation: Your Name, You. (2009). \"Paper Title Number 1.\" <i>Journal 1</i>. 1(1)."
     ]
    }
   ],
   "source": [
    "!cat ../_publications/2009-10-01-paper-title-number-1.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
